{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"pip\" non � riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "import pickle\n",
    "import networkx\n",
    "import openai\n",
    "import random\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x227d66ec130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caricamento del knowledge graph da un file pickle\n",
    "def load_knowledge_graph(file_path):\n",
    "    with open(file_path, 'rb') as graph_file:\n",
    "        return pickle.load(graph_file)\n",
    "\n",
    "G = load_knowledge_graph(r'C:\\Users\\Simone\\Documents\\Desktop\\Tesi_Magistrale\\KG.pickle')\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation claims -Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai le relazioni dal grafo\n",
    "def extract_relations_from_graph(G):\n",
    "    relations = []\n",
    "    for subject, object, data in G.edges(data=True):\n",
    "        predicate = data['label']  # Assumendo che ogni edge abbia un attributo 'label' per il predicato\n",
    "        relations.append((subject, predicate, object))\n",
    "    return relations\n",
    "\n",
    "# Utilizza questa funzione per ottenere le tue relazioni\n",
    "knowledge_graph_relations = extract_relations_from_graph(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_true_statement_prompt(relation):\n",
    "    subject, predicate, object = relation\n",
    "    # Assicurati che il prompt sia in inglese\n",
    "    return f\"Create a sentence that accurately describes the relationship: '{subject}' {predicate.lower()} '{object}'.\"\n",
    "\n",
    "def generate_false_statement_prompt(relation):\n",
    "    subject, predicate, object = relation\n",
    "    # Genera un prompt in inglese che chiede per una affermazione falsa\n",
    "    return f\"Generate a false statement involving '{subject}' and '{object}' but not related by '{predicate}'.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_statements(relations, n, true=True):\n",
    "    statements = []\n",
    "    for _ in range(n):\n",
    "        relation = random.choice(relations)\n",
    "        prompt_text = generate_true_statement_prompt(relation) if true else generate_false_statement_prompt(relation)\n",
    "        \n",
    "        # Modifica qui per usare l'endpoint di chat\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",  # Sostituisci con il nome corretto del modello di chat se necessario\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt_text}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # L'accesso alla risposta potrebbe dover essere leggermente modificato a seconda della struttura dell'output\n",
    "        statement = response.choices[0].message['content'].strip()\n",
    "        label = \"Vera\" if true else \"Falsa\"\n",
    "        statements.append((statement, label))\n",
    "    return statements\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumi che `knowledge_graph_relations` sia già definito come mostrato precedentemente\n",
    "true_statements = generate_statements(knowledge_graph_relations, 10, true=True)\n",
    "false_statements = generate_statements(knowledge_graph_relations, 10, true=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"The \\'Macaca mulatta\\' is part of the \\'Entire amnion\\'.\"', 'Vera'),\n",
       " ('The male population group is the location for studying the biochemical presence of N-acetyl-3-methylhistidine.',\n",
       "  'Vera'),\n",
       " ('\"Corticotropin interacts with Atrial Natriuretic Factor in the body\\'s hormonal system.\"',\n",
       "  'Vera'),\n",
       " (\"'Heptanol' and 'Adrenergic beta-Agonists' coexist within the same biological or pharmaceutical context.\",\n",
       "  'Vera'),\n",
       " (\"'The level of exertion can influence the activity of the PIK3CB wt Allele|AKT1.'\",\n",
       "  'Vera'),\n",
       " ('\"A young adult is potentially susceptible to the onset of Acute Posterior Multifocal Placoid Pigment Epitheliopathy.\"',\n",
       "  'Vera'),\n",
       " ('\"Infiltration often occurs simultaneously in the development and progression of Merkel cell carcinoma.\"',\n",
       "  'Vera'),\n",
       " ('The Retinoblastoma Protein, RB1, interacts with the NDRG1 gene, NDRG1.',\n",
       "  'Vera'),\n",
       " ('The Calcium Channel is located in the Epithelium.', 'Vera'),\n",
       " ('\"Methanol is located in the breast cancer cell.\"', 'Vera')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('All boys are born with Chagas Disease.', 'Falsa'),\n",
       " ('The Transjugular intrahepatic portosystemic shunt procedure is a diagnostic tool to check the condition of the entire gastrointestinal tract.',\n",
       "  'Falsa'),\n",
       " ('\"Pain management techniques directly increase insulin sensitivity in the body.\"',\n",
       "  'Falsa'),\n",
       " ('Partial excision can be performed without the use of any histological techniques.',\n",
       "  'Falsa'),\n",
       " ('\"ATE1 is the only protein responsible for the development of Malignant Neoplasms.\"',\n",
       "  'Falsa'),\n",
       " ('An Assay can be used to play the sounds of an Oropharyngeal instrument.',\n",
       "  'Falsa'),\n",
       " ('The Agent is a type of Pheochromocytoma.', 'Falsa'),\n",
       " ('Granzyme B is produced by Tertiary Lymphoid Structures.', 'Falsa'),\n",
       " ('\"Pharmacological stimulation always inhibits the contraction of muscles.\"',\n",
       "  'Falsa'),\n",
       " ('Paraplegia causes weakness in the arms.', 'Falsa')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triple Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")\n",
    "gen_kwargs = {\n",
    "    \"max_length\": 256,\n",
    "    \"length_penalty\": 0,\n",
    "    \"num_beams\": 3,\n",
    "    \"num_return_sequences\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_extraction(text):\n",
    "    # Tokenizza il testo\n",
    "    model_inputs = tokenizer(text, max_length=256, padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Genera\n",
    "    generated_tokens = model.generate(\n",
    "        input_ids=model_inputs[\"input_ids\"].to(model.device),\n",
    "        attention_mask=model_inputs[\"attention_mask\"].to(model.device),\n",
    "        **gen_kwargs,\n",
    "    )\n",
    "\n",
    "    # Decodifica\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "    # Estrai le triple\n",
    "    triplets = []\n",
    "    for sentence in decoded_preds:\n",
    "        triplets.extend(extract_triplets(sentence))\n",
    "\n",
    "    return triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head': 'Paraplegia', 'type': 'has effect', 'tail': 'weakness in the arms'}\n",
      "{'head': 'Paraplegia', 'type': 'has effect', 'tail': 'weakness in the arms'}\n",
      "{'head': 'weakness in the arms', 'type': 'has cause', 'tail': 'Paraplegia'}\n",
      "{'head': 'Paraplegia', 'type': 'subclass of', 'tail': 'weakness in the arms'}\n"
     ]
    }
   ],
   "source": [
    "# Testo di esempio\n",
    "text_example = \"Paraplegia causes weakness in the arms.\"\n",
    "\n",
    "# Applica l'estrazione al testo di esempio\n",
    "triplets_extracted = apply_extraction(text_example)\n",
    "\n",
    "# Stampa le triple estratte\n",
    "for triplet in triplets_extracted:\n",
    "    print(triplet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
